---
title: "Homework 4"
author: "Lauren Lazaro"
output: github_document
---

```{r}
library(BSDA)
library(tidyverse)
library(readr)
```


## Problem 1

A new device has been developed which allows patients to evaluate their blood sugar levels.  The most widely device currently on the market yields widely variable results. The new device is evaluated by 25 patients having nearly the same distribution of blood sugar levels yielding the following data:

125 123 117 123 115 112 128 118 124
111 116 109 125 120 113 123 112 118
121 118 122 115 105 118 131

a) Is there significant ($\alpha = 0.05$) evidence that median blood sugar readings was less than 120 in the population from which the 25 patients were selected?  Use the sign test and report the test statistic and p-value.

b) Is there significant ($\alpha = 0.05$) evidence that median blood sugar readings was less than 120 in the population from which the 25 patients were selected?  Use the Wilcoxon signed-rank test and report the test statistic and p-value.

## Part a
```{r, echo= FALSE, warning = FALSE, message = FALSE}
device = c(125 ,123, 117, 123, 115, 112, 128 ,118, 124, 111 ,116 ,109, 125, 120, 113, 123, 112, 118,
121, 118, 122, 115, 105, 118, 131)

exactly_120 = sum(device == 120)
over_120 = sum(device > 120)

```

There is one value that is exactly 120 and 10 values that are over 120. n* = 24 and C = 10. We fail to reject H0 because C is between 6.7 and 17.3. Thus, there is not enough evidence to prove that the median blood sugar is less than 120 in the population.

## Part b
```{r}
wilcox = wilcox.test(device, mu = 120, conf.level = 0.95)

wilcox
```

Results show a p-value of 0.1447. This value is larger than alpha so we can fail to reject the null hypothesis. There is not enough evidence to show that the median blood sugar reading is less than 120 in the population. 

## Problem 2 

Human brains have a large frontal cortex with excessive metabolic demands compared with the brains of other primates. However, the human brain is also three or more times the size of the brains of other primates. Is it possible that the metabolic demands of the human frontal cortex are just an expected consequence of greater brain size? A data file containing the measurements of glia-neuron ratio (an indirect measure of the metabolic requirements of brain neurons) and the log-transformed brain mass in nonhuman primates was provided to you along with the following graph.

a)  Fit a regression model for the nonhuman data using $\ln{(\textrm{brain mass})}$ as a predictor.  (Hint: Humans are "homo sapiens".)
b) Using the nonhuman primate relationship, what is the predicted glia-neuron ratio for humans, given their brain mass?
c) Determine the most plausible range of values for the prediction.  Which is more relevant for your prediction of human glia-neuron ratio: an interval for the predicted mean glia-neuron ratio at the given brain mass, or an interval for the prediction of a single new observation?
d) Construct the 95% interval chosen in part (c).  On the basis of your result, does the human brain have an excessive glia-neuron ratio for its mass compared with other primates?

## Part a
```{r}
#| echo: false
#| message: false
#| fig.width: 2.5
#| fig.height: 2
#| fig.align: "center"
#| fig.pos: "h"

brain = readxl::read_xlsx("/Users/laurenlazaro/Desktop/R/biostats/data/Brain.xlsx")

brain |>  
  slice(-1) |>  
  ggplot(aes(x = `Ln Brain mass`, y = `Glia-neuron ratio`)) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  geom_point(color = "red") +
  geom_point(aes(x = brain$`Ln Brain mass`[1], 
                 y = brain$`Glia-neuron ratio`[1])) +
  guides(color = "none") +
  theme_classic()
```

## Part b
```{r}
brain_dat = 
  brain |> 
  janitor::clean_names() |> 
  filter(species != "Homo sapiens") 

brain_dat[is.na(brain_dat) | brain_dat=="Inf"] = NA

brain_fig =
  lm(glia_neuron_ratio ~ ln_brain_mass, data = brain_dat) 
summary(brain_fig)

brain_mass = 1373
log_mass = log(brain_mass)
predicted = predict(brain_fig, newdata = data.frame(ln_brain_mass = log_mass))

print(predicted)

# the predicted ratio of glia neuron is 1.472319
```

## Part c
We should use a prediction interval because we are interested in getting a range for a new,
individual data point (not the predicted mean of glia-neuron ratio).

## Part d
```{r}
range =
  predict(brain_fig, newdata = data.frame(ln_brain_mass = log_mass), interval = "prediction", level = 0.95)
print(range)
```

In a 95% CI, we know that the ratio of the glia neuron is between 1.04 and 1.91. The upper bound of the CI is 1.91 which is higher than the other ratios corresponding to primates. Thus, the human brain has a larger glia neuron ratio compared to other primates.



## Problem 3 

For this problem, you will be using data `HeartDisease.csv`. The investigator is mainly interested if there is an association between ‘total cost’ (in dollars) of patients diagnosed with heart disease and the ‘number of emergency room (ER) visits’. Further, the model will need to be adjusted for other factors, including ‘age’, ‘gender’, ‘number of complications’ that arose during treatment, and ‘duration of treatment condition’.

a) Provide a short description of the data set: what is the main outcome, main predictor and other important covariates. Also, generate appropriate descriptive statistics for all variables of interest (continuous and categorical) – no test required.
b) Investigate the shape of the distribution for variable `totalcost` and try different transformations, if needed.
c) Create a new variable called `comp_bin` by dichotomizing ‘complications’: 0 if no complications, and 1 otherwise.
d) Based on your decision in part (b), fit a simple linear regression (SLR) between the original or transformed `totalcost` and predictor `ERvisits`. This includes a scatterplot and results of the regression, with appropriate comments on significance and interpretation of the slope.
e) Fit a multiple linear regression (MLR) with `comp_bin` and `ERvisits` as predictors.
  i) Test if `comp_bin` is an effect modifier of the relationship between `totalcost` and `ERvisits`. Comment.
  ii) Test if `comp_bin` is a confounder of the relationship between `totalcost` and `ERvisits`. Comment.
  iii) Decide if `comp_bin` should be included along with `ERvisits`. Why or why not?
f) Use your choice of model in part (e) and add additional covariates (age, gender, and duration of treatment).
  i) Fit a MLR, show the regression results and comment.
  ii) Compare the SLR and MLR models. Which model would you use to address the investigator’s objective and why?

## Part a
```{r}
library(readr)
heart = 
  read_csv("/Users/laurenlazaro/Desktop/R/biostats/data/HeartDisease.csv")
```

The main outcome of the heart dataset is the total cost of treating heart disease. The main predictor is the number of ER visits and duration of stay. Most of the vairables are categorical, but ER visits and duration are continous variables.

## Part b
```{r}

heart |> 
 mutate(gender1 = sum(gender),
        gender1prop = sum(gender)/n()) |> 
 summarise(mean_cost = mean(totalcost),
           mean_ERvisits = mean(ERvisits),
           mean_age = mean(age),
           gender1prop = mean(gender1prop),
           mean_complications = mean(complications),
           mean_duration = mean(duration)) 


ggplot(aes(x = totalcost), data = heart) +
 geom_histogram()
```

## Part c
```{r}
heart =
  heart |> 
  mutate(comp_bin = as.factor(if_else(complications == 0, 0, 1)))
```

## Part d
```{r}
SLR = lm(totalcost ~ ERvisits, data = heart)
summary(SLR)


heart |> 
   ggplot(aes(x = ERvisits, y = totalcost)) + geom_point(color='purple') +
   theme_bw() +
   geom_smooth(method='lm', se=FALSE, color='red') +
   labs(x="ER Visits", y="Total Cost (ln)")
```

## Part e
```{r}
fit2 =
  lm(totalcost ~ ERvisits + comp_bin, data = heart)
summary(fit2) 

fit3 = lm(totalcost ~ ERvisits * comp_bin, data = heart)
summary(fit3)

fit4 = lm(totalcost ~ ERvisits + comp_bin, data = heart)
summary(fit4)
```
 
The results in fit3 show there is no significant interaction between the variables ERvisits and comp_bin. The p-value is not significant when comparing it to alpha. Thus, we do not have evidence that the coefficient does not equal 0. We can conclude that comp_bin is not an effect modifier between ERvisits and totalcost and we can remove this term from out model.

## Part f
```{r}
fit_mlr = lm(totalcost ~ ERvisits + comp_bin + age + factor(gender) + duration, data = heart)
summary(fit_mlr)


#age, gender, and duration of treatment are all very important to analyze when
#looking at total cost. They should be included in the model and can provide 
#some very useful information and analysis. I would use MLR model beacuse it 
#shows more accurately all the factors affecting total cost and is better for 
#analysis.  
```

Age, gender, and duration of treatment are all very important to analyze when looking at total cost. They should be included in the model and can provide very useful information and analysis. 

```{r}
anova(SLR, fit_mlr)
```

The MLR model has an adjusted R^2 of 0.2452 which is larger than the adjusted R^2 value of the SLR model of 0.0836. This means that the MLR model explains about 25% of the variation in total cost compared to the SLR model which can only explain 8%. Thus, MLR is preferred. 
